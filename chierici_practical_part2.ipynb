{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TJfNUgelLKKI"
   },
   "source": [
    "# <center>Machine learning from scratch - Part II</center>\n",
    "## <center>WebValley 2019 - AI for Health @ Casez, Italy</center>\n",
    "### <center>Marco Chierici & Margherita Francescatto</center>\n",
    "#### <center>FBK/MPBA</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t1GLtJ7YLKKJ"
   },
   "source": [
    "Recap. We are using a subset of the SEQC neuroblastoma data set [Zhang et al, Genome Biology, 2015] consisting of 272 samples (136 training, 136 test). The data was preprocessed a bit to facilitate the progress of the tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6Dhu_6_ULKKK"
   },
   "source": [
    "We start by loading the modules we need to process the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jT_SUG13LKKL"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd ## for reading text files and manipulating data frames\n",
    "from sklearn import neighbors ## kNN classifier\n",
    "from sklearn import svm ## SVM classifier\n",
    "from sklearn.ensemble import RandomForestClassifier ## RF classifier\n",
    "from sklearn.model_selection import cross_val_score ## needed to train in CV\n",
    "from bokeh.io import output_notebook, show\n",
    "from bokeh.plotting import figure\n",
    "np.random.seed(42) ## set random seed just in case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1001\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1001\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        root._bokeh_is_loading--;\n",
       "        if (root._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"1001\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.0.4.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-1.0.4.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.4.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.4.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.4.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.4.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.4.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };var element = document.getElementById(\"1001\");\n  if (element == null) {\n    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n    return false;\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.0.4.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-1.0.4.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.4.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.4.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.4.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.4.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.4.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qOlPPJmmLKKO"
   },
   "source": [
    "Define files to read:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  for convenience, define the data directory as a variable\n",
    "DATA_DIR = \"NB_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cnidnnC4LKKP"
   },
   "outputs": [],
   "source": [
    "DATA_TR = DATA_DIR + \"MAV-G_272_tr.txt\"\n",
    "DATA_TS = DATA_DIR + \"MAV-G_272_ts.txt\"\n",
    "LABS_TR = DATA_DIR + \"labels_tr.txt\"\n",
    "LABS_TS = DATA_DIR + \"labels_ts.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yd4YsVYnLKKS"
   },
   "source": [
    "Read in the files as _pandas dataframes_ (they are conceptually like R data frames):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SBBKnUO-LKKS"
   },
   "outputs": [],
   "source": [
    "data_tr = pd.read_csv(DATA_TR, sep = \"\\t\")\n",
    "data_ts = pd.read_csv(DATA_TS, sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2QiDbifgLKKV"
   },
   "source": [
    "Since we already looked at the data in the first part of the dataset, we move directly to the juicy stuff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nY4Jcd9XLKKW"
   },
   "source": [
    "We drop the first column from the train and test expression sets, since it's just the sample IDs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Ejm4N6xLKKW"
   },
   "outputs": [],
   "source": [
    "data_tr = data_tr.drop('sampleID',axis =1)\n",
    "data_ts = data_ts.drop('sampleID',axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q6DrKsxlLKKZ"
   },
   "source": [
    "...and store the data into Numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mua2Ajr-LKKa"
   },
   "outputs": [],
   "source": [
    "x_tr = data_tr.values\n",
    "x_ts = data_ts.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6yvTIil4LKKc"
   },
   "source": [
    "Now we read in the files containing labels and select the column with the CLASS target to do our first round of analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "69bKNl0QLKKe"
   },
   "outputs": [],
   "source": [
    "labs_tr = pd.read_csv(LABS_TR, sep = \"\\t\")\n",
    "labs_ts = pd.read_csv(LABS_TS, sep = \"\\t\")\n",
    "class_lab_tr = labs_tr[['CLASS']]\n",
    "class_lab_ts = labs_ts[['CLASS']]\n",
    "y_tr = class_lab_tr.values.ravel()\n",
    "y_ts = class_lab_ts.values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "arErpTdvLKKh"
   },
   "source": [
    "In the previous part of the tutorial, we focused on the k-NN classifiers. In the previous lecture, however, we explored theoretical aspects related to two other broadly used classifiers: Support Vector Machines (SVMs) and Random Forests (RFs). In this second part of tutorial, the first thing we want to do is assessing how these two alternative classification methods perform on our neuroblastoma dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zMP7DMy3LKKh"
   },
   "source": [
    "We start with SVM. We first rescale the data, import the relevant model and create an instance of the SVM classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "## first you need to create a \"scaler\" object\n",
    "scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "## then you actually scale data by fitting the scaler object on the data\n",
    "scaler.fit(x_tr)\n",
    "x_tr = scaler.transform(x_tr)\n",
    "x_ts = scaler.transform(x_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oY93_AikLKKj"
   },
   "outputs": [],
   "source": [
    "## import support vector classifier (SVC) and create an instance\n",
    "from sklearn.svm import SVC\n",
    "svc = SVC(random_state=42, verbose=1, kernel='linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pseq_nh7LKKl"
   },
   "source": [
    "Note that the specification _kernel = 'linear'_ implies that a linear kernel will be used. If you remember from the lecture, this means that a linear function is used to define the decision boundaries of the classifier. Alternatives include _‘poly’_ and _‘rbf’_ for polynomial or gaussian kernels respectively. Scikit-learn offers an alternative implementation of linear SVMs. You can find more details in Scikit User Guide. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "waXcgaLpLKKm"
   },
   "source": [
    "As previously done with the k-NN classifier, we fit the SVM and get the predictions for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qqc3TmFBLKKn",
    "outputId": "d9ef6c64-9f18-4bea-9167-decaa0ca1820"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    }
   ],
   "source": [
    "## fit the model and get the predictions\n",
    "svc.fit(x_tr, y_tr)\n",
    "class_pred_ts = svc.predict(x_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lI7vGjulLKKr"
   },
   "source": [
    "Now we give a look at the classification metrics introduced in the first part of the tutorial. to access the functions, we need to load the metrics module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ku0JSF_ALKKs",
    "outputId": "94585c0e-534a-445d-d0ba-92a9bf3a9388"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC =  0.8857501367027195\n",
      "ACC =  0.9485294117647058\n",
      "SENS =  0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print('MCC = ', metrics.matthews_corrcoef(class_lab_ts, class_pred_ts))\n",
    "print('ACC = ', metrics.accuracy_score(class_lab_ts, class_pred_ts))\n",
    "print('SENS = ', metrics.recall_score(class_lab_ts, class_pred_ts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1JnMF6UoLKKw"
   },
   "source": [
    "We can also give a look at the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "whSZnHGALKKx",
    "outputId": "2c471734-3504-4af7-8ebb-74e5a02be301"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92        46\n",
      "           1       0.97      0.96      0.96        90\n",
      "\n",
      "   micro avg       0.95      0.95      0.95       136\n",
      "   macro avg       0.94      0.95      0.94       136\n",
      "weighted avg       0.95      0.95      0.95       136\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(class_lab_ts, class_pred_ts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K6ZZSMPkLKKz"
   },
   "source": [
    "Exercise: **one-shot Random Forest classification**. _Hint:_ the RF classifier is implemented in the Scikit learn class RandomForestClassifier, from _sklearn.ensemble_ module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZT6XjB20LKK0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC =  0.9029628032413496\n",
      "ACC =  0.9558823529411765\n",
      "SENS =  0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "## space for exercise\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier as rfc\n",
    "clf = rfc(n_estimators=501)\n",
    "clf.fit(x_tr,y_tr)\n",
    "y_ts = clf.predict(x_ts)\n",
    "\n",
    "print('MCC = ', metrics.matthews_corrcoef(class_lab_ts, y_ts))\n",
    "print('ACC = ', metrics.accuracy_score(class_lab_ts, y_ts))\n",
    "print('SENS = ', metrics.recall_score(class_lab_ts, class_pred_ts, y_ts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6khMtHGSLKK3"
   },
   "source": [
    "## Parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XlHdQ4xSLKK4"
   },
   "source": [
    "As mentioned in the lecture, Scikit learn offers a very useful and flexible tool for parameter tuning called _GridSearchCV_. While the tool is very sophisticated and efficient, it is useful to at least try an example _by hand_ to understand what is happening in the background.\n",
    "\n",
    "For this example we use a linear SVM and try to tune the C parameter. You might remember from the lectures that the paramenter C essentially controls how much we want to avoid misclassifying each training example. Large values of C result in smaller margins, i.e. closer fitting to the training data. As mentioned in the classes, the drawback is over-fitting, resulting in poor generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XG01P5fdLKK6",
    "outputId": "099e6404-c7fd-414a-b49a-4092af095c57",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C =  1e-06\n",
      "MCC =  0.8075728530872482\n",
      "ACC =  0.9117647058823529\n",
      "SENS =  1.0 \n",
      "\n",
      "C =  1e-05\n",
      "MCC =  0.9175607547892035\n",
      "ACC =  0.9632352941176471\n",
      "SENS =  0.9777777777777777 \n",
      "\n",
      "C =  0.0001\n",
      "MCC =  0.9175607547892035\n",
      "ACC =  0.9632352941176471\n",
      "SENS =  0.9777777777777777 \n",
      "\n",
      "C =  0.001\n",
      "MCC =  0.9175607547892035\n",
      "ACC =  0.9632352941176471\n",
      "SENS =  0.9777777777777777 \n",
      "\n",
      "C =  0.01\n",
      "MCC =  0.9175607547892035\n",
      "ACC =  0.9632352941176471\n",
      "SENS =  0.9777777777777777 \n",
      "\n",
      "C =  0.1\n",
      "MCC =  0.9175607547892035\n",
      "ACC =  0.9632352941176471\n",
      "SENS =  0.9777777777777777 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## define the sequence of C values we want to use in the search of the best one\n",
    "C_list = [0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1]\n",
    "for C in C_list:\n",
    "    print('C = ', C)\n",
    "    svc = svm.SVC(kernel = 'linear', C=C)\n",
    "    svc.fit(x_tr, class_lab_tr.values.ravel())\n",
    "    class_pred_ts = svc.predict(x_ts)\n",
    "    print('MCC = ', metrics.matthews_corrcoef(class_lab_ts, class_pred_ts))\n",
    "    print('ACC = ', metrics.accuracy_score(class_lab_ts, class_pred_ts))\n",
    "    print('SENS = ', metrics.recall_score(class_lab_ts, class_pred_ts), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hhn8hFrJLKK-"
   },
   "source": [
    "From C = 1e-03 the classification performance reaches a plateau. C = 1e-04 yields the highest MCC on the test set: when tuning the parameters we would consider this as the best choice for the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oh8VvvpcLKK_"
   },
   "source": [
    "**Exercise:** as you already saw in the lectures, there are many parameters that can be tuned, also when considering only one simple classifier. For example, if you consider SVM with 'rbf' kernel, you could check performance changes with different values of C **and** gamma, for example using two nested loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BPtC-EBSLKK_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C =  1e-06\n",
      "gamma =  0.001\n",
      "MCC =  0.8075728530872482\n",
      "ACC =  0.9117647058823529\n",
      "SENS =  1.0 \n",
      "\n",
      "gamma =  0.01\n",
      "MCC =  0.8075728530872482\n",
      "ACC =  0.9117647058823529\n",
      "SENS =  1.0 \n",
      "\n",
      "gamma =  0.1\n",
      "MCC =  0.8075728530872482\n",
      "ACC =  0.9117647058823529\n",
      "SENS =  1.0 \n",
      "\n",
      "gamma =  1\n",
      "MCC =  0.8075728530872482\n",
      "ACC =  0.9117647058823529\n",
      "SENS =  1.0 \n",
      "\n",
      "C =  1e-05\n",
      "gamma =  0.001\n",
      "MCC =  0.9175607547892035\n",
      "ACC =  0.9632352941176471\n",
      "SENS =  0.9777777777777777 \n",
      "\n",
      "gamma =  0.01\n",
      "MCC =  0.9175607547892035\n",
      "ACC =  0.9632352941176471\n",
      "SENS =  0.9777777777777777 \n",
      "\n",
      "gamma =  0.1\n",
      "MCC =  0.9175607547892035\n",
      "ACC =  0.9632352941176471\n",
      "SENS =  0.9777777777777777 \n",
      "\n",
      "gamma =  1\n",
      "MCC =  0.9175607547892035\n",
      "ACC =  0.9632352941176471\n",
      "SENS =  0.9777777777777777 \n",
      "\n",
      "C =  0.0001\n",
      "gamma =  0.001\n",
      "MCC =  0.9175607547892035\n",
      "ACC =  0.9632352941176471\n",
      "SENS =  0.9777777777777777 \n",
      "\n",
      "gamma =  0.01\n",
      "MCC =  0.9175607547892035\n",
      "ACC =  0.9632352941176471\n",
      "SENS =  0.9777777777777777 \n",
      "\n",
      "gamma =  0.1\n",
      "MCC =  0.9175607547892035\n",
      "ACC =  0.9632352941176471\n",
      "SENS =  0.9777777777777777 \n",
      "\n",
      "gamma =  1\n",
      "MCC =  0.9175607547892035\n",
      "ACC =  0.9632352941176471\n",
      "SENS =  0.9777777777777777 \n",
      "\n",
      "C =  0.001\n",
      "gamma =  0.001\n",
      "MCC =  0.9175607547892035\n",
      "ACC =  0.9632352941176471\n",
      "SENS =  0.9777777777777777 \n",
      "\n",
      "gamma =  0.01\n",
      "MCC =  0.9175607547892035\n",
      "ACC =  0.9632352941176471\n",
      "SENS =  0.9777777777777777 \n",
      "\n",
      "gamma =  0.1\n",
      "MCC =  0.9175607547892035\n",
      "ACC =  0.9632352941176471\n",
      "SENS =  0.9777777777777777 \n",
      "\n",
      "gamma =  1\n",
      "MCC =  0.9175607547892035\n",
      "ACC =  0.9632352941176471\n",
      "SENS =  0.9777777777777777 \n",
      "\n",
      "C =  0.01\n",
      "gamma =  0.001\n",
      "MCC =  0.9175607547892035\n",
      "ACC =  0.9632352941176471\n",
      "SENS =  0.9777777777777777 \n",
      "\n",
      "gamma =  0.01\n",
      "MCC =  0.9175607547892035\n",
      "ACC =  0.9632352941176471\n",
      "SENS =  0.9777777777777777 \n",
      "\n",
      "gamma =  0.1\n",
      "MCC =  0.9175607547892035\n",
      "ACC =  0.9632352941176471\n",
      "SENS =  0.9777777777777777 \n",
      "\n",
      "gamma =  1\n",
      "MCC =  0.9175607547892035\n",
      "ACC =  0.9632352941176471\n",
      "SENS =  0.9777777777777777 \n",
      "\n",
      "C =  0.1\n",
      "gamma =  0.001\n",
      "MCC =  0.9175607547892035\n",
      "ACC =  0.9632352941176471\n",
      "SENS =  0.9777777777777777 \n",
      "\n",
      "gamma =  0.01\n",
      "MCC =  0.9175607547892035\n",
      "ACC =  0.9632352941176471\n",
      "SENS =  0.9777777777777777 \n",
      "\n",
      "gamma =  0.1\n",
      "MCC =  0.9175607547892035\n",
      "ACC =  0.9632352941176471\n",
      "SENS =  0.9777777777777777 \n",
      "\n",
      "gamma =  1\n",
      "MCC =  0.9175607547892035\n",
      "ACC =  0.9632352941176471\n",
      "SENS =  0.9777777777777777 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## space for exercise\n",
    "C_list = [0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1]\n",
    "gamma_list = [0.001,0.01,0.1,1]\n",
    "for C in C_list:\n",
    "    print('C = ', C)\n",
    "    for gamma in gamma_list:\n",
    "        print('gamma = ', gamma)\n",
    "        svc = svm.SVC(kernel = 'linear', C=C, gamma=gamma)\n",
    "        svc.fit(x_tr, class_lab_tr.values.ravel())\n",
    "        class_pred_ts = svc.predict(x_ts)\n",
    "        print('MCC = ', metrics.matthews_corrcoef(class_lab_ts, class_pred_ts))\n",
    "        print('ACC = ', metrics.accuracy_score(class_lab_ts, class_pred_ts))\n",
    "        print('SENS = ', metrics.recall_score(class_lab_ts, class_pred_ts), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hJC3MFEALKLB"
   },
   "source": [
    "As we mentioned, Scikit offers fully automated parameter tuning engine. We illustrate its power with a simple example on our data. We use GridSearchCV to search through a grid of C and gamma parameter options for SVM with 'rbf' kernel. In order to do this we define a small function svc_param_selection that does the work for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "utM1ALBfLKLC",
    "outputId": "d96dc041-2f6f-4f1a-bca5-70310d1f79ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.001, 'gamma': 0.001}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def svc_param_selection(X, y, nfolds):\n",
    "    Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "    gammas = [0.001, 0.01, 0.1, 1]\n",
    "    param_grid = {'C': Cs, 'gamma' : gammas}\n",
    "    grid_search = GridSearchCV(svm.SVC(kernel='rbf'), param_grid, cv=nfolds, n_jobs=4)\n",
    "    grid_search.fit(X, y)\n",
    "    grid_search.best_params_\n",
    "    return grid_search.best_params_\n",
    "\n",
    "svc_param_selection(x_tr, y_tr, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tI_6v1jNLKLF"
   },
   "source": [
    "## Feature ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HcQ4gJjgLKLG"
   },
   "source": [
    "As mentioned in the lecture, random forests have a built-in tool for feature ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2lZAaTXJLKLH",
    "outputId": "2155231c-e50c-4c06-82c4-6b6a5f7c4ee2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a forest and compute the feature importances\n",
    "rf = RandomForestClassifier(n_estimators=250)\n",
    "rf.fit(x_tr, y_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7gH9yIYOLKLJ"
   },
   "source": [
    "For the sake of completeness make the predictions and check the classification performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rspvHmO0LKLK",
    "outputId": "7b131d8f-ebc8-4d03-9f38-ad90de735367"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC =  0.8845305105723343\n",
      "ACC =  0.9485294117647058\n",
      "SENS =  0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "class_pred_ts = rf.predict(x_ts)\n",
    "print('MCC = ', metrics.matthews_corrcoef(class_lab_ts, class_pred_ts))\n",
    "print('ACC = ', metrics.accuracy_score(class_lab_ts, class_pred_ts))\n",
    "print('SENS = ', metrics.recall_score(class_lab_ts, class_pred_ts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m3k78HePLKLT"
   },
   "source": [
    "Now extract the feature importances and display the first 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7g9k5EHsLKLU",
    "outputId": "aa26094b-0e4a-48f0-be91-ecd2874ab204"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking (top 10 features):\n",
      "1. feature 3972 (0.009295)\n",
      "2. feature 13513 (0.008621)\n",
      "3. feature 23751 (0.007907)\n",
      "4. feature 2979 (0.007825)\n",
      "5. feature 8570 (0.007552)\n",
      "6. feature 641 (0.007123)\n",
      "7. feature 563 (0.006740)\n",
      "8. feature 3426 (0.006341)\n",
      "9. feature 5013 (0.006288)\n",
      "10. feature 5712 (0.006168)\n"
     ]
    }
   ],
   "source": [
    "importances = rf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking (top 10 features):\")\n",
    "for f in range(10):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VX9otFjOLKLX"
   },
   "source": [
    "Would be nice to know to which genes they actually correspond. If you remember the gene names are the column names of the pandas dataframe containing the training/test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2fSkitN7LKLY",
    "outputId": "73191a71-9657-4582-ede6-7fb14cd3fc05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slartoybo.Gene_AceView\n",
      "DLGAP5.Gene_AceView\n",
      "LOC728688.Gene_AceView\n",
      "MINK1.Gene_AceView\n",
      "CKS2.Gene_AceView\n",
      "PHB.Gene_AceView\n",
      "KIF5A.Gene_AceView\n",
      "RRM1.Gene_AceView\n",
      "EPN2.Gene_AceView\n",
      "LOC100190939.Gene_AceView\n"
     ]
    }
   ],
   "source": [
    "columnsNamesArr = data_tr.columns.values\n",
    "for i in range(10):\n",
    "    print(columnsNamesArr[indices[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kkgGzniAP6y4"
   },
   "source": [
    "## Extra exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uSW_fBLwP-fO"
   },
   "source": [
    "The classification task considered so far (CLASS) is quite easy, since the classes reflect extreme disease outcomes (favorable vs unfavorable).\n",
    "\n",
    "A more interesting task could be the prediction of Event-Free Survival (EFS). To do this, an extended version of the dataset is provided in the `/data/marco` directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QfYqaV0ZP9Y-"
   },
   "outputs": [],
   "source": [
    "DATA_TR = DATA_DIR + \"full_MAV-G_498_tr.csv\"\n",
    "DATA_TS = DATA_DIR + \"full_MAV-G_498_ts.csv\"\n",
    "LABS_TR = DATA_DIR + \"full_labels_tr.txt\"\n",
    "LABS_TS = DATA_DIR + \"full_labels_ts.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L7i0MA0FSa7Z"
   },
   "source": [
    "Read the data in (take note of the input data format) and prepare the `x_tr`, `x_ts`,  `y_tr`, `y_ts` Numpy arrays, as before, using \"EFS\" as target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UNpBL3UDS8dI"
   },
   "source": [
    "Recalling concepts from the first practical, perform an explorative PCA analyisis, plotting the first two components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zNfPACYqTOT4"
   },
   "source": [
    "Train a kNN classifier in one-shot mode: fit the model on the training set and predict the labels on the test set. Compute performance metrics using the provided true labels of the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6OkabT2FTvPT"
   },
   "source": [
    "Experiment with different classifier(s) and/or different parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tHhMWGSLUXS5"
   },
   "source": [
    "Try tuning the parameter(s) (e.g. using GridSearchCV) and find the optimal parameter set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_vk_ChapUzbP"
   },
   "source": [
    "Using the optimal parameters, run a 10x iterated 5-fold cross-validation on the training set; compute the average cross-validation metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NjyflIl5VF2Y"
   },
   "source": [
    "Using the optimal parameters, train a model on the whole training set and predict the labels of the test set. Compute the metrics and compare them with the average cross-validation metrics. What do you expect? Use the trained model to rank the features and inspect the top ones."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "practical_neuroblastoma_partII_v0.3.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
